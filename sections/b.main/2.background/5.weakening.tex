
Axiom weakening, as discussed in this thesis, is based on the approach presented for weakening with \ALC ontologies in \cite{troquard2018repairing}. To provide the necessary context for the following discussion on how weakening may be performed in \SROIQ, we provide a brief overview of axiom weakening in the case of \ALC. For further details, see \cite{troquard2018repairing}.
%
We begin by defining subconcepts. We will immediately also extend the definition to \SROIQ concepts, since we will need it for later definitions of axiom weakening in \SROIQ.

\begin{definition}
  Let $\Omc$ be an \ALC or \SROIQ ontology. The set of \emph{subconcepts} of $\Omc$ is given by
  \begin{align*}
    \sub(\Omc) = \{\top, \bot\} \cup \bigcup_{C(a) \in \Omc} \sub(C) \cup \bigcup_{C \sqsubseteq D \in \Omc} ( \sub(C) \cup \sub(D) ) \enspace,
  \end{align*}
  where $\sub(C)$ is the set of \emph{subconcepts} in $C$ given by
  \begin{widepage}
    \vspace{-5mm}
    \begin{align*}
      \sub(A) &= \{ A \} \quad , A \in N_C \cup \{ \top, \bot \} \enspace, &
      \sub(\lnot C) &= \{ \lnot C \} \cup \sub(C) \enspace, \\
      \sub(C \sqcup D) &= \{ C \sqcup D \} \cup \sub(C) \cup \sub(D) \enspace, &
      \sub(\forall R.C) &= \{ \forall R.C \} \cup \sub(C) \enspace, \\
      \sub(C \sqcap D) &= \{ C \sqcap D \} \cup \sub(C) \cup \sub(D) \enspace, &
      \sub(\exists R.C) &= \{ \exists R.C \} \cup \sub(C) \enspace, \\
      \sub(\more n R.C) &= \{ \more n R.C \} \cup \sub(C) \enspace, &
      \sub(\less n R.C) &= \{ \less n R.C \} \cup \sub(C) \enspace, \\
      \sub(\exists R.\self) &= \{ \exists R.\self \} \enspace, &
      \sub(\nominal a) &= \{ \nominal a \} \enspace.
    \end{align*}
  \end{widepage}
\end{definition}

% define upward and downward covers
Let us now define the so-called upward and downward cover sets of concepts. The upward cover for a given concept is the set of the most specific generalizations from the (fixed) set of subconcepts, while the downward cover set contains the most general specializations from the same set of subconcepts. (It should be noted that the related open search for, e.g., a least common subsumer is in general a harder problem \cite{baader2003least}.)

\begin{definition} \label{def:alc-covers}
  Let $\Omc$ be an \ALC ontologies that uses the vocabulary $N_C$, $N_R$, and $N_I$. The \emph{upward cover} and \emph{downward cover} for a concept $C$ are given by
  \begin{align*}
    \UpC_\Omc(C) = \{ & D \in \sub(\Omc) \mid C \sqsubseteq_\Omc D \text{ and } \\
    & \nexists D' \in \sub(\Omc) \text{ with } C \sqsubset_\Omc D' \sqsubset_\Omc D \} \enspace, \\
    \DownC_\Omc(C) = \{ & D \in \sub(\Omc) \mid D \sqsubseteq_\Omc C \text{ and } \\
    & \nexists D' \in \sub(\Omc) \text{ with } D \sqsubset_\Omc D' \sqsubset_\Omc C \} \enspace.
  \end{align*}
\end{definition}

Note here that the upward and downward covers will only yield useful results if the ontology $\Omc$ is consistent. Since they operate only over the subconcepts of $\Omc$, on their own, the upward and downward covers of concepts are missing some interesting refinements.
\begin{example} \label{ex:up-cover-alc}
  Let $N_C = \{ A, B, C \}$, $N_R = \{ r \}$, and $\Omc = \{ A \sqsubseteq B \}$. $\sub(\Omc) = \{\top, \bot, A, B\}$. The upward cover of $C \sqcup A$ is equal to $\UpC_\Omc(C \sqcup A) = \{ \top \}$. The potential refinement to $C \sqcup B$ will be missed even by iterated application of the upward cover because $C \sqcup B \not\in \sub(\Omc)$. Similarly, $\UpC_\Omc(\forall r.A) = \{ \top \}$, even though $\forall r.B$ is a reasonable generalization.
\end{example}

% define the abstract refinement operator
% define the concrete generalization and specialization operator
To additionally capture these omissions, we define generalization and specialization operators that recursively exploit the complex structure of the concept expressions being refined to generate more interesting refinements.

\begin{definition}
  Let $\refine$ and $\corefine$ be two functions taking concept expressions as parameters and mapping them to finite sets of concepts.
  The \emph{abstract refinement operator} is defined recursively on the structure of concept expressions, as follows.
  \begin{align*}
    \zeta_{\refine,\corefine}(A) ={} & \refine(A) \quad, A \in N_C \cup \{\top, \bot\} \enspace, \\
    \zeta_{\refine,\corefine}(\lnot C) ={} & \refine(\lnot C) \cup \{ \lnot C' \mid C' \in \zeta_{\corefine,\refine}(C) \} \enspace, \\
    \zeta_{\refine,\corefine}(C \sqcap D) ={} & \refine(C \sqcap D) \cup \{ C' \sqcap D \mid C' \in \zeta_{\refine,\corefine}(C) \} \\
    & \cup \{ C \sqcap D' \mid D' \in \zeta_{\refine,\corefine}(D) \} \enspace, \\
    \zeta_{\refine,\corefine}(C \sqcup D) ={} & \refine(C \sqcup D) \cup \{ C' \sqcup D \mid C' \in \zeta_{\refine,\corefine}(C) \} \\
    & \cup \{ C \sqcup D' \mid D' \in \zeta_{\refine,\corefine}(D) \} \enspace, \\
    \zeta_{\refine,\corefine}(\forall R.C) ={} & \refine(\forall R.C)
    \cup \{ \forall R.C' \mid C' \in \zeta_{\refine,\corefine}(C) \} \enspace, \\
    \zeta_{\refine,\corefine}(\exists R.C) ={} & \refine(\exists R.C)
    \cup \{ \exists R.C' \mid C' \in \zeta_{\refine,\corefine}(C) \} \enspace.
  \end{align*}
  Using the abstract refinement operator $\zeta_{\refine,\corefine}$, we build two concrete refinement operators. The \emph{generalization operator} and \emph{specialization operator} are, respectively, defined as
  \begin{align*}
    \gamma_\Omc &= \zeta_{\UpC_\Omc,\DownC_\Omc} \enspace \text{and} \enspace
    \rho_\Omc = \zeta_{\DownC_\Omc,\UpC_\Omc} \enspace.
  \end{align*}
\end{definition}

If we again revisit the example in \cref{ex:up-cover-alc}, we can observe that $\gamma_\Omc(C \sqcup A) = \{ \top, \top \sqcup A, C \sqcup A, C \sqcup B \}$ does contain the possible refinement $C \sqcup B$. Similarly, $\gamma_\Omc(\forall r.A) = \{ \top, \forall r.A, \forall s.A, \forall r.B \}$ contains $\forall r.B$. Some basic properties of $\gamma_\Omc$ and $\rho_\Omc$ are shown in \cite{troquard2018repairing}. Most relevant of these is the fact that $\gamma_\Omc$ and $\rho_\Omc$ do in fact return, respectively, generalizations and specializations of the given concepts. Formally, for all concepts $C$ and $D$, if $D \in \gamma_\Omc(C)$ then $C \sqsubseteq_\Omc D$. Similarly, if $D \in \rho_\Omc$ then $D \sqsubseteq_\Omc C$. Another important property to take note of is that both concrete refinement operators only return finite sets of refinements.

% define the weakening operator
We define now the \emph{axiom weakening operator} using these generalization and specialization operators.

\begin{definition}
  Given an axiom $\alpha$, the set of \emph{weakenings} with respect to the ontology $\Omc$, written $g_\Omc(\alpha)$, is defined such that
  \begin{align*}
    g_\Omc(C \sqsubseteq D) ={} & \{ C' \sqsubseteq D \mid C' \in \rho_\Omc (C) \} \\
    & \cup \{ C \sqsubseteq D' \mid D' \in \gamma_\Omc(D) \} \enspace, \\
    g_\Omc(C(a)) ={} & \{ C'(a) \mid C' \in \gamma_\Omc(C) \} \enspace.
  \end{align*}
\end{definition}

The axioms in the set $g_\Omc(\alpha)$ are indeed weaker than $\alpha$ for every axiom $\alpha$, in the sense that, given the reference ontology $\Omc$, $\alpha$ entails them and the opposite is not necessarily true. That is, for each axiom $\alpha' \in g_\Omc(\alpha)$, $\alpha \models\Omc \alpha'$ holds.

\begin{example}
  Let $N_C = \{ A, B, C \}$, $N_I = \{ a \}$ and $\Omc = \{ A \sqsubseteq B, A \sqsubseteq C \}$. $\sub(\Omc) = \{\top, \bot, A, B, C\}$. $\gamma_\Omc(A) = \{ A, B, C \}$ and $\rho_\Omc(B) = \{ B, A \}$. The weakenings of $B \sqsubseteq A$ with respect to $\Omc$ are therefore $g_\Omc(B \sqsubseteq A) = \{ B \sqsubseteq A, B \sqsubseteq B, B \sqsubseteq C, A \sqsubseteq A \}$. Similarly, $g_\Omc(A(a)) = \{ A(a), B(a), C(a) \}$.
\end{example}

In order to apply the weakening operator to the problem of repairing inconsistent ontologies, we follow the algorithm depicted in \cref{algo:repair-weaken-alc}. First, as mentioned above, the computation of a non-trivial upward and downward cover set is only possible when using a consistent ontology. We, therefore, need to first find a consistent subontology $\Omcref$ of $\Omc$ to serve as \emph{reference ontology}. One possibility outlined in \cite{troquard2018repairing} is to select a random maximal consistent subset of $\Omc$. Another option is to choose the intersection of some (or all) maximal consistent subsets of $\mathcal{O}$ (e.g., \cite{LLRRS10}). This latter option has the advantage of using only information for the weakening that is likely to be correct. On the other hand, it will lead to diminished upward and downward covers and therefore can reduce the number of possible weakenings.

Once a reference ontology has been chosen, and as long as $\Omc$ is inconsistent, we continue by selecting a ``bad axiom'' $\alpha$, remove it from $\Omc$, and replace it with a weaker axiom from $g_\Omcref(\alpha)$. As for the choice of reference ontology, there are also multiple options for the selection of bad axioms. \cite{troquard2018repairing} proposes two different implementations. One is based on choosing axioms at random, and another implementation randomly samples a number of (or all the) minimal inconsistent subsets of axioms $J_1, J_2, \dots, J_k \subseteq \Omc$ and returns one axiom from the ones occurring the most often. The weaker axiom is chosen from the set of weakening by selecting one uniformly at random. While there may be better heuristics for choosing the weakening, termination of the algorithm is not generally guaranteed. It has, however, been shown in \cite{confalonieri2020towards}, that when selecting among the weakening at random using a uniform distribution, their algorithm is almost surely going to terminate. It has yet to be shown whether this holds also for the variation presented in this paper. A similar effect of almost sure termination could also be achieved by maintaining a constant non-zero probability of removing the axiom at each step.

\begin{algorithm}[ht]
  \begin{algorithmic}
    \State $\Omcref \gets \textsc{FindConsistentSubset}(\Omc)$
    \While{$\Omc$ is inconsistent}
      \State $\alpha_\textnormal{bad} \gets \textsc{FindBadAxiom}(\Omc)$
      \State $\alpha_\textnormal{weaker} \gets \textsc{SelectWeakerAxiom}(g_\Omcref(\alpha_\textnormal{bad}))$
      \State $\Omc \gets (\Omc \setminus \{\alpha_\textnormal{bad}\}) \cup \{\alpha_\textnormal{weaker}\}$
    \EndWhile
    \State Return $\Omc$
  \end{algorithmic}
  \caption{$\textsc{RepairOntologyWeaken}(\Omc)$}
  \label{algo:repair-weaken-alc}
\end{algorithm}

\begin{example}\label{ex:alc-weakening}
  Given the inconsistent ontology $\Omc = \{ A \sqsubseteq B \sqcap \lnot C, B \sqsubseteq C, A(a) \}$, we want to repair it such that it becomes consistent. We select first a maximal consistent subset as reference ontology $\Omcref = \{ B \sqsubseteq C, A(a) \}$. To find a bad axiom, we sample all minimal inconsistent subsets. Since removing any of the axioms makes it consistent, there is only one minimal inconsistent subset $J_1 = \Omc$. Say we choose the axiom $A \sqsubseteq B \sqcap \lnot C$ and weaken it to $A \sqsubseteq C \sqcap \lnot C$. The ontology is still inconsistent, with the single minimal inconsistent subset $J_1 = \{ A \sqsubseteq C \sqcap \lnot C, A(a) \}$. Let us choose to weaken $A(a)$ to $\top(a)$. The ontology is now consistent.
\end{example}

While the repair using axiom weakening is capable of preserving more information than removal, as has been empirically shown in \cite{troquard2018repairing}, this is influenced significantly by the choice of which axioms to weaken and which weaker axioms to use. In fact, computing a maximal consistent subset may in some cases lead to a more gentle repair than applying the procedure outlined above in \cref{algo:repair-weaken-alc}. This can be seen in \cref{ex:alc-weakening}, where the last replacement alone would have restored consistency, and the information lost in the previous replacement could have been preserved.
