
As established in \cref{ontology-bugs}, maintaining the consistency and correctness of ontologies can be a difficult task. Ontology repair is the process of automatically correcting these inconsistencies or errors in ontologies. Several approaches have been proposed for ontology repair. This section will explore some of these approaches and their underlying principles.

\subsection{Basic Definitions} \label{basic-definitions}

We define a repair as proposed in \cite{baader2018making}. It is assumed, as is the case for most DLs, that there exists a monotone consequence operator $\models$ such that for any two ontologies $\Omc_1 \subseteq \Omc_2$ and axiom $\alpha$, $\Omc_1 \models \alpha$ implies $\Omc_2 \models \alpha$. Additionally, $\op{Con}(\Omc)$ shall contain all consequences of $\Omc$, that is $\op{Con}(\Omc) = \{ \alpha \mid \Omc \models \alpha \}$. We split the ontology further into two disjoint sets $\Omc = \Omc_s \cup \Omc_r$ of \emph{static axioms} $\Omc_s$ and \emph{refutable axioms} $\Omc_r$. Static axioms are assumed to be correct and may not be touched by the repair procedure, while refutable axioms are possibly be erroneous. This separation is useful for example if the static part of the ontology is hand-crafted, while the refutable part is automatically generated. Similarly, it is applicable in case multiple ontologies are combined, and some sources are seen as less trustworthy than others.

\begin{definition}
  Given an ontology $\Omc = \Omc_s \cup \Omc_r$ and an unintended consequence $\Omc \models \alpha$, $\Omc_s \not\models \alpha$, the ontology $\Omc_s \subseteq \Omc'$ is a \emph{repair} of $\Omc$ with respect to $\alpha$ if $\op{Con}(\Omc') \subseteq \op{Con}(\Omc) \setminus \{\alpha\}.$ A repair $\Omc'$ is an \emph{optimal repair} of $\Omc$ with respect to $\alpha$ if there exists no other repair $\Omc_s \subseteq \Omc''$ such that $\op{Con}(\Omc') \subset \op{Con}(\Omc'') \subseteq \op{Con}(\Omc) \setminus \{\alpha\}$.
\end{definition}

Given that $\Omc_s \not\models \alpha$, a repair is guaranteed to exist, since $\Omc_s$ is one such repair. On the other hand, as has been shown in \cite{baader2018making}, generally an optimal repair does not necessary need to exist.

\begin{example}\label{ex:no-optimal}
  Given the vocabulary $N_C = \{ A \}$ and $N_I = \{ a \}$, let the ontology $\Omc = \Omc_s \cup \Omc_r$ be made up of the static axioms $\Omc_s = \{ A \sqsubseteq \exists r.A, \exists r.A \sqsubseteq A \}$ and refutable axioms $\Omc_r = \{ A(a) \}$. Let $\alpha = A(a)$ be an unintended consequence of $\Omc$. In this case, the ontology $\Omc' = \Omc_s \cup \{ (\exists r.\top) (a) \}$ is a possible repair. However, using any axioms $((\exists r.)^n\top) (a)$ also yields a valid repair. Since for every repair using $((\exists r.)^n\top) (a)$ there exists a repair using $((\exists r.)^{n + 1}\top) (a)$ that has more consequences, there exists no optimal repair.
\end{example}

It should be noted also that there exists an infinite number of possible repairs, as adding tautologies to a repair will always yield another valid repair. In the case that we are interested in making an inconsistent ontology consistent, we can use as $\alpha$ any unsatisfiable axiom, e.g., $\top \sqsubseteq \bot$. Since all axioms, including unsatisfiable axioms, are entailed by inconsistent ontologies, a repair that does not entail $\alpha$ is consistent. Notice also that in this case where $\Omc$ is inconsistent, any consistent ontology that does not entail $\alpha$, even if completely unrelated to $\Omc$, will be a repair of $\Omc$. It will be assumed in the rest of this thesis that unless otherwise noted all axioms of an ontology are refutable, and that the unintended consequence is the inconsistency of the ontology.

In contrast, the classical approach to repair consists of identifying and removing problematic axioms (e.g, \cite{schlobach2003non,kalyanpur2005debugging,kalyanpur2006repairing,BaPS07}). As such, a classical repair is always a subset of the original ontology and the number of classical repairs for any pair $\Omc$ and $\alpha$ is necessarily finite.

\begin{definition}
  Given an ontology $\Omc = \Omc_s \cup \Omc_r$ and an unintended consequence $\Omc \models \alpha$, $\Omc_s \not\models \alpha$, the ontology $\Omc_s \subseteq \Omc' \subseteq \Omc$ is a \emph{classical repair} of $\Omc$ with respect to $\alpha$ if $\op{Con}(\Omc') \subseteq \op{Con}(\Omc) \setminus \{\alpha\}.$ A classical repair $\Omc'$ is an \emph{optimal classical repair} of $\Omc$ with respect to $\alpha$ if there exists no other classical repair $\Omc_s \subseteq \Omc'' \subseteq \Omc$ such that $\op{Con}(\Omc') \subset \op{Con}(\Omc'') \subseteq \op{Con}(\Omc) \setminus \{\alpha\}$.
\end{definition}

We can observe that every classical repair is in fact a valid repair. It follows that also a classical repair is guaranteed to exist. Unlike for the general case of optimal repairs, an optimal classical repair is always guaranteed to exist. This follows from the fact that the set of classical repairs is finite, and the $\subset$ relation is a strict partial order, so there can not be an infinite sequence of classical repairs $\Omc^{(1)}, \Omc^{(2)}, \dots$  such that $\op{Con}(\Omc^{(i)}) \subset \op{Con}(\Omc^{(i + 1)})$.

\subsection{Repair Approaches} \label{repair-approaches}

\subsubsection{Classical Repairs} \label{classical-repairs}

Generating a classical repair can be achieved in a number of equivalent ways. One way to compute an optimal classical repair is using justifications and hitting sets \cite{reiter1987theory}.

\begin{definition}
  Given an ontology $\Omc = \Omc_s \cup \Omc_r$ and an axiom $\Omc \models \alpha$, $\Omc_s \not\models \alpha$, a \emph{justification} for $\alpha$ in $\Omc$ is a minimal subset $J \subseteq \Omc_r$ such that $J \cup \Omc_s \models \alpha$. Given the set of all justifications $J_1, \dots, J_n$ for $\alpha$ in $\Omc$, a \emph{hitting set} $H$ for these justifications is a set of axioms such that $H \cap J_i \not= \empty$ for $i = 1, \dots, n$. $H$ is a \emph{minimal hitting} set if it does not strictly contain another hitting set.
\end{definition}

\begin{example}
  Given the vocabulary $N_C = \{ C, D \}$ and $N_I = \{ a \}$, the ontology $\Omc = \{ D \sqsubseteq \lnot C, D(a), C(a) \}$ is inconsistent. A possible (optimal) classical repair to restore the consistency is $\Omc' = \{ D(a), C(a) \}$.
\end{example}

Justifications are necessarily non-empty since $\Omc_s \not\models \alpha$, and therefore hitting sets and minimal hitting sets always exist. Given any minimal hitting set $H$ for the justification $J_1, \dots, J_n$ of $\alpha$ in $\Omc$, the ontology $\Omc' = \Omc \setminus H$ is an optimal classical repair of $\Omc$ with respect to $\alpha$.

This algorithm for computing optimal classical repairs requires the computation of all justifications, which can in general be very computationally intensive. Black-box approaches for computing justifications have been proposed \cite{kalyanpur2007finding,schlobach2003non,schlobach2007debugging} that compute justifications by repeatedly making calls to pre-existing highly-optimized reasoners. These may however, in the worst-case, need to make an exponential number of calls to the reasoner. Nevertheless, in practice they may often be fast enough, as for example the hitting set tree base algorithm presented in \cite{kalyanpur2007finding}, which conveniently can compute both all justifications and all hitting sets. There exist also glass-box approach to computing justifications \cite{kalyanpur2007finding}, that require only a single reasoning request to find justifications, but they also require specialized, generally less efficient, reasoners.

An alternative to computing all justification is to directly find a minimal correction subset $C$ of $\Omc_r$ such that $\Omc \setminus C \not\models \alpha$. Finding a single such set can be done efficiently using similar algorithms to the ones for finding single justifications. Algorithms for solving the minimal subsets over monotone predicate problem, such as the \textsc{QuickXplain} algorithm \cite{junker2004preferred} or a progression-based algorithm \cite{marques2013minimal} may be used. A subset of all such sets can be found efficiently using the \textsc{MergeXplain} algorithm \cite{shchekotykhin2015mergexplain}. Of course, computing all minimal correction subsets directly is also possible, using similar algorithms to the ones used for computing all justifications \cite{malouf2007maximal}.

\subsubsection{More Gentle Repairs} \label{more-gentle-repairs}

While the classical approach is obviously sufficient to guarantee that a possible repair is found, it can lead to unnecessary information loss. That is, the repaired ontology might be missing some consequences of the original ontology that were actually desirable, and did not necessarily have to be removed in order to find a repair.

\begin{example}
  Given the inconsistent ontology $\Omc = \{ \top \sqsubseteq C \sqcap D, C \sqcap D \sqsubseteq \bot \}$, we want to repair it such that it becomes consistent. To repair this ontology using a classical repair, we have to remove one of the two axioms. However, to make the ontology consistent it would be sufficient to remove one of the disjuncts in first axiom.
\end{example}

Since ideally, one wants to retain as much information as possible, alternative methods for repairing ontologies have been proposed that are able to preserve more information than the classical approach (e.g., \cite{du2014practical,AMAI-2018,baader2018making,troquard2018repairing,confalonieri2020towards,horridge2008laconic,lam2008fine}).

One option is to first modify the original ontology and afterwards apply the classical repair approach. The intuition is that in the modified ontology the individual axioms should contain less information, and therefore, the removal of axioms leads to less information loos relative to the unmodified ontology. In \cite{horridge2008laconic} the authors propose a structural transformation, that replaces axioms with a set of weaker axioms that are semantically equivalent, but on their own contain less information.

\begin{example}
  Given the inconsistent ontology $\Omc = \{ A \sqsubseteq B \sqcap \lnot C, B \sqsubseteq C, A(a) \}$, we want to repair it such that it becomes consistent. To repair this ontology using a classical repair, we have to remove one of the three axioms. However, we can transform it into the equivalent ontology $\Omc' = \{ A \sqsubseteq B, A \sqsubseteq \lnot C, B \sqsubseteq C, A(a) \}$. Now, we have some additional possibilities. We could for example remove only the axiom $A \sqsubseteq \lnot C$ and retain the consequence $C(a)$ which would otherwise have always been lost.
\end{example}

Another approach to repairing ontologies more gently that has been proposed in the literature is using \emph{axiom weakening} \cite{troquard2018repairing,confalonieri2020towards,baader2018making,lam2008fine}. Instead of removing axioms, they are replaced with weaker axioms. Replacing an axiom with a weaker axiom can not cause new consequences, but may diminish the set of consequences.

\begin{definition}
  An axiom $\alpha$ is \emph{weaker} that another axioms $\alpha'$ with respect to some ontology $\Omc$ if and only if for every model $I \models \Omc$ of $\Omc$, $I \models \alpha$ implies $I \models \alpha'$. Equivalently we write $\alpha \models_\Omc \alpha'$.
\end{definition}

In \cite{lam2008fine} the authors show a method for pinpointing the causes for unsatisfiability within axioms, and propose a way of weakening axioms guided by this information. The authors of \cite{baader2018making} show general theoretical results for repair using axiom weakening, and propose a concrete weakening relation for the DL $\mathcal{EL}$. They further show that the repair algorithm using the proposed axiom weakening terminates in at most an exponential number of weakening steps. \cite{troquard2018repairing} presents the repair of inconsistent ontologies using axiom weakening with the help of refinement operators. It is further empirically shown in \cite{troquard2018repairing} that weakening axioms can retain significantly more information compared to removing them. This approach is later extended in \cite{confalonieri2020towards} to cover more expressive DLs, including most concepts of \SROIQ. Additionally, in \cite{confalonieri2020towards} it is shown that the proposed repair algorithm using axiom weakening will almost surely, i.e., with probability $1$, terminate.

Whether optimal repairs exist for these axiom weakening based approaches depends largely on which method is used for selecting weaker axioms. Replacement of the axioms with tautologies is one trivial form of axiom weakening, and equivalent to generating classical repairs. On the other hand, the axiom weakening based repair approaches studied in \cite{troquard2018repairing,confalonieri2020towards} and the one used in this thesis do not necessarily guarantee the existence of an optimal repair. This can be seen from the fact that \cref{ex:no-optimal} is applicable also to those algorithms.
